{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid/ Softmax/ Log Likelihood/ NLL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random number of datapoints and a random number of classes\n",
    "n_batch = 6\n",
    "n_classes = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.8462,  0.6815,  0.4842],\n",
       "        [ 0.1994, -0.2347, -0.8847],\n",
       "        [ 2.3776, -0.8194,  2.2221],\n",
       "        [-0.9184, -0.0412,  2.5192],\n",
       "        [ 0.7622,  0.8399, -0.6373],\n",
       "        [-0.3377,  0.5634, -0.8695]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simulate a classification problem\n",
    "activations = torch.randn((n_batch, n_classes))\n",
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 1., 0.],\n",
       "        [1., 0., 0.],\n",
       "        [1., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define seed for reproductibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define the corresponding targets\n",
    "targets = torch.zeros_like(activations)\n",
    "\n",
    "# Define two lists for indexing xs and ys\n",
    "# In ys, simulate only one class from n_classes for the respective datapoints\n",
    "row_indices = range(n_batch)\n",
    "col_indices = np.array(np.random.rand(1, n_batch)  // (1. / n_classes), dtype = np.int)\n",
    "\n",
    "# Use the lists to index into targets and define them accordingly\n",
    "targets[row_indices, col_indices] = 1\n",
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid\n",
    "\n",
    "The sigmoid function is defined as follows\n",
    "\n",
    "$$ sigmoid(x) = \\frac{1}{1 + e^{-x}} $$\n",
    "\n",
    "It only considers one output at a time because of which the output probabilities don't sum to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3002, 0.6641, 0.6187],\n",
       "        [0.5497, 0.4416, 0.2922],\n",
       "        [0.9151, 0.3059, 0.9022],\n",
       "        [0.2853, 0.4897, 0.9255],\n",
       "        [0.6818, 0.6985, 0.3459],\n",
       "        [0.4164, 0.6372, 0.2954]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the sigmoid activations\n",
    "activations.sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3002, 0.6641, 0.6187],\n",
       "        [0.5497, 0.4416, 0.2922],\n",
       "        [0.9151, 0.3059, 0.9022],\n",
       "        [0.2853, 0.4897, 0.9255],\n",
       "        [0.6818, 0.6985, 0.3459],\n",
       "        [0.4164, 0.6372, 0.2954]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify using the formula\n",
    "1 / (1 + torch.exp(-activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(1 / (1 + torch.exp(-activations)), activations.sigmoid())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax\n",
    "\n",
    "Softmax function is defined for a range of activations. If there are several activations $x_1, x_2, x_3, ..., x_n$ then softmax of an activation is defined as \n",
    "\n",
    "$$softmax(x) = \\frac{e^x}{\\Sigma_{i=1}^{n}(e^x)}$$\n",
    "\n",
    "This squishes the activations to be in the range from 0 - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1065, 0.4907, 0.4028],\n",
       "        [0.5035, 0.3262, 0.1703],\n",
       "        [0.5272, 0.0216, 0.4513],\n",
       "        [0.0290, 0.0697, 0.9014],\n",
       "        [0.4296, 0.4644, 0.1060],\n",
       "        [0.2469, 0.6080, 0.1451]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = activations.softmax(dim = 1)\n",
    "sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.0287,  4.0287,  4.0287],\n",
       "        [ 2.4243,  2.4243,  2.4243],\n",
       "        [20.4469, 20.4469, 20.4469],\n",
       "        [13.7769, 13.7769, 13.7769],\n",
       "        [ 4.9879,  4.9879,  4.9879],\n",
       "        [ 2.8892,  2.8892,  2.8892]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the denominators by summing across the columns for each row\n",
    "drs = torch.ones_like(activations)\n",
    "drs = drs * torch.exp(activations).sum(dim = 1).unsqueeze(1)\n",
    "drs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1065, 0.4907, 0.4028],\n",
       "        [0.5035, 0.3262, 0.1703],\n",
       "        [0.5272, 0.0216, 0.4513],\n",
       "        [0.0290, 0.0697, 0.9014],\n",
       "        [0.4296, 0.4644, 0.1060],\n",
       "        [0.2469, 0.6080, 0.1451]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify using the formula\n",
    "torch.exp(activations) / drs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if our manual way and torch's internal way match\n",
    "assert torch.allclose(torch.exp(activations) / drs, activations.softmax(dim = 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss\n",
    "\n",
    "Very popularly used for classification problems, cross entropy loss is defined as follows\n",
    "\n",
    "$$ Cross \\ Entropy \\ Loss = -\\Sigma_{i = 1}^{n}{t_i}log(p_i)$$\n",
    "\n",
    "where \n",
    "- n is the total number of classes\n",
    "- t is the truth value of the ith class\n",
    "- p is the probability of the ith class\n",
    "\n",
    "In a single label classification problem, only one class has $t_i = 0$ and the rest of activations are all zeros. This reduces the loss further down to have only one term which is the log of the probability score of the target for that datapoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually perform cross entropy steps\n",
    "\n",
    "- Index into softmax activations and pick probabilities corresponding to target values\n",
    "- Take a log of these indexed softmax activations\n",
    "- Sum the series and negate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4907, 0.1703, 0.4513, 0.0697, 0.4296, 0.2469]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the terms corresponding to the target indices\n",
    "probas = sm[range(n_batch), col_indices]\n",
    "probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7120, -1.7703, -0.7957, -2.6642, -0.8448, -1.3987]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a log of these values\n",
    "log_probas = torch.log(probas)\n",
    "log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7120, 1.7703, 0.7957, 2.6642, 0.8448, 1.3987]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the negative log likelihood\n",
    "neg_log_probas = -1 * log_probas\n",
    "neg_log_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1857)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sum the losses and negate it\n",
    "loss_value = neg_log_probas.sum() \n",
    "loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use internal cross entropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7120, 1.7703, 0.7957, 2.6642, 0.8448, 1.3987])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See losses for each individual datapoint\n",
    "torch.nn.CrossEntropyLoss(reduction = 'none')(activations, tensor(col_indices[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1857)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the overall loss by summing across all the elements\n",
    "torch.nn.CrossEntropyLoss(reduction = 'sum')(activations, tensor(col_indices[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use internal log_softmax and nll_loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7120, 1.7703, 0.7957, 2.6642, 0.8448, 1.3987])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Individual datapoint loss\n",
    "l_sm = F.log_softmax(activations, dim = 1)\n",
    "F.nll_loss(l_sm, tensor(col_indices[0]), reduction = 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.1857)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative loss\n",
    "l_sm = F.log_softmax(activations, dim = 1)\n",
    "F.nll_loss(l_sm, tensor(col_indices[0]), reduction = 'sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fastai convenience functions\n",
    "\n",
    "There are a lot of convenience functions defined in the `fastcore.basics` module which can come in very handy for several operations especially when processing the data.\n",
    "\n",
    "We shall have a look at the following ones which I envision to be really handy\n",
    "\n",
    "- L: It is a class which is very much like a list but slightly better.\n",
    "- listify/tuplify: It is a function which converts any collection/iterable into a list/tuple\n",
    "- uniqueify: It is a function that grabs all the unique items from a collection\n",
    "- last_index: Find the last occurence of an element in a collection\n",
    "- filter_dict: Filters the kv pairs of a dictionary based on a function taking k,v as arguments\n",
    "- filter_keys: Filters the kv pairs of a dictionary based on a function that takes k as arguments\n",
    "- filter_values: Filters the kv pairs of a dictionary based on a function that takes v as arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastai` has introduced a really nice wrapper around python's list class called `L`. It is functionally the same as a list but it's more convenient to work with. Let me show you with an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.PETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/samoyed_48.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/chihuahua_119.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_82.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Bengal_182.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/keeshond_190.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/english_setter_96.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Bengal_75.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/saint_bernard_195.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Siamese_80.jpg')...]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"images\").ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts any given collection into a list\n",
    "listify(set({1,2,3,4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k', 'v']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listify({\"k\":2, \"v\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listify((1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Converts any given collection into a tuple\n",
    "tuplify(set({1,2,3,4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('k', 'v')"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuplify({\"k\":2, \"v\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 4)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuplify([1, 2, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 2]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabs a list of all the unique elements in a provided collection\n",
    "uniqueify([3,1,2,3,1,3,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tells where the query last occurred in the collection\n",
    "last_index(2, [1,2,3,4,1,1,2,3,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dictionary\n",
    "d = {\"Fruit: Apple\":5, \"Fruit: Bananas\":4, \"Menu: Apple Pie\":34, \"Ingredient: Butter\": 32, \"Ingredient: Salt\": 5}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fruit: Apple': 5, 'Fruit: Bananas': 4}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out only fruits from the dictionary\n",
    "fruit = lambda query: re.match(r\"Fruit: \\w+\", query)\n",
    "filter_keys(d, fruit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Fruit: Apple': 5, 'Fruit: Bananas': 4}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out only items with less than 10 units cost\n",
    "cost = lambda query: query < 10\n",
    "filter_values(d, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ingredient: Salt': 5}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter out ingredients with cost less than 10 units\n",
    "cheap_ingredient = lambda k, v: re.match(r\"Ingredient: \\w+\", k) and v < 10\n",
    "filter_dict(d, cheap_ingredient) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regular Expressions\n",
    "\n",
    "Regexes short for regular expressions are a language in themselves. They are a language which specifies a set of rules for representation of common language strings like English in a particular syntax.\n",
    "\n",
    "This can help us find if a given word/phrase/sentence(more generally strings) contains a particular pattern that we want to be there and more powerfully, extract such patterns whenever they're encountered from such strings.\n",
    "\n",
    "Let us play around with the pets dataset URLs using regex to understand the importance of this language and subsequently how this could help us in Deep Learning.\n",
    "\n",
    "Here is a really good one stop resource for understanding different characters/patterns in regex which can help create our custom query patterns for string matching.\n",
    "\n",
    "[Data Quest Regex Cheatsheet](https://www.dataquest.io/wp-content/uploads/2019/03/python-regular-expressions-cheat-sheet.pdf)\n",
    "\n",
    "In python, we have the module called `re` which comes in pre-built that could be used to leverage regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/annotations')]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/samoyed_48.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/chihuahua_119.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/american_pit_bull_terrier_82.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Bengal_182.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/keeshond_190.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/english_setter_96.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Bengal_75.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/saint_bernard_195.jpg'),Path('/home/vinayak/.fastai/data/oxford-iiit-pet/images/Siamese_80.jpg')...]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = path/\"images\"\n",
    "images_path.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paths in `oxford-iiit dataset` are named in a very `structured` way. This helps us leverage regex to understand more about the dataset.\n",
    "\n",
    "Precisely the way data is structured is:\n",
    "- The name of all dog breed files start with a small letter\n",
    "- The name of all files is in the format \\<breed\\>_\\<number\\>.jpg\n",
    "- If the breed is a multiple word breed, then the breed will be represented by `_` in between words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex to get all the cat files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','Bengal_182.jpg','keeshond_190.jpg','english_setter_96.jpg','Abyssinian_101.mat','Bengal_75.jpg','saint_bernard_195.jpg','Siamese_80.jpg'...]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames = L([x.name for x in images_path.ls()])\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) [[],[],[],['Bengal_182.jpg'],[],[],['Abyssinian_101.mat'],['Bengal_75.jpg'],[],['Siamese_80.jpg']...]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pattern = r\"[A-Z].+\"\n",
    "cats = L([re.findall(cat_pattern, x) for x in filenames])\n",
    "cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2403) ['Bengal_182.jpg','Abyssinian_101.mat','Bengal_75.jpg','Siamese_80.jpg','Bombay_164.jpg','Ragdoll_118.jpg','Siamese_126.jpg','Bengal_1.jpg','Birman_17.jpg','Russian_Blue_47.jpg'...]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = L([x[0] for x in cats if len(x) > 0])\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex to get all the cat breeds\n",
    "\n",
    "Now that we have cat files, we can get the cat breeds from these using another regex as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','Bengal_182.jpg','keeshond_190.jpg','english_setter_96.jpg','Abyssinian_101.mat','Bengal_75.jpg','saint_bernard_195.jpg','Siamese_80.jpg'...]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_breed_pattern = r\"(^[A-Z].+)_\\d+\"\n",
    "cat_breeds = L([re.findall(cat_breed_pattern, x) for x in filenames])\n",
    "cat_breeds = L([x[0] for x in cat_breeds if len(x) > 0])\n",
    "cat_breeds = L(uniqueify(cat_breeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#12) ['Bengal','Abyssinian','Siamese','Bombay','Ragdoll','Birman','Russian_Blue','Egyptian_Mau','Maine_Coon','Persian'...]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex to get all the dog breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','Bengal_182.jpg','keeshond_190.jpg','english_setter_96.jpg','Abyssinian_101.mat','Bengal_75.jpg','saint_bernard_195.jpg','Siamese_80.jpg'...]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "dog_breed_pattern = r\"(^[a-z].+)_\\d+\"\n",
    "dog_breeds = L([re.findall(dog_breed_pattern, x) for x in filenames])\n",
    "dog_breeds = L([x[0] for x in dog_breeds if len(x) > 0])\n",
    "dog_breeds = L(uniqueify(dog_breeds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#25) ['samoyed','chihuahua','american_pit_bull_terrier','keeshond','english_setter','saint_bernard','boxer','great_pyrenees','basset_hound','leonberger'...]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_breeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using regex to get all dogs and all cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','Bengal_182.jpg','keeshond_190.jpg','english_setter_96.jpg','Abyssinian_101.mat','Bengal_75.jpg','saint_bernard_195.jpg','Siamese_80.jpg'...]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#4990) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','keeshond_190.jpg','english_setter_96.jpg','saint_bernard_195.jpg','boxer_36.jpg','great_pyrenees_175.jpg','chihuahua_105.jpg','basset_hound_23.jpg'...]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dog_pattern = r\"^[a-z].+_\\d+.jpg\"\n",
    "dogs = L([re.findall(dog_pattern, x) for x in filenames])\n",
    "dogs = L([x[0] for x in dogs if len(x) > 0])\n",
    "dogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2400) ['Bengal_182.jpg','Bengal_75.jpg','Siamese_80.jpg','Bombay_164.jpg','Ragdoll_118.jpg','Siamese_126.jpg','Bengal_1.jpg','Birman_17.jpg','Russian_Blue_47.jpg','Egyptian_Mau_171.jpg'...]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_pattern = r\"^[A-Z].+_\\d+.jpg\"\n",
    "cats = L([re.findall(cat_pattern, x) for x in filenames])\n",
    "cats = L([x[0] for x in cats if len(x) > 0])\n",
    "cats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the union of cats and dogs equals all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7390"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2400+4990"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#7393) ['samoyed_48.jpg','chihuahua_119.jpg','american_pit_bull_terrier_82.jpg','Bengal_182.jpg','keeshond_190.jpg','english_setter_96.jpg','Abyssinian_101.mat','Bengal_75.jpg','saint_bernard_195.jpg','Siamese_80.jpg'...]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Abyssinian_100.mat', 'Abyssinian_101.mat', 'Abyssinian_102.mat'}"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(filenames).difference(set(cats).union(set(dogs)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "294.075px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
